# Chunk 1: setup
knitr::opts_chunk$set(echo = TRUE)
# Chunk 2
#Inspecting the data
#Remember to install these packages if you haven't already done so
library(foreign)
library(pastecs) #For creating descriptive statistic summaries
library(ggplot2) #For creating histograms with more detail than plot
library(psych) # Some useful descriptive functions
library(semTools) #For skewness and kurtosis
library(car) # For Levene's test for homogeneity of variance
#Read in the file
regression <- read.spss("Regression.sav", use.value.labels=TRUE, max.value.labels=Inf, to.data.frame=TRUE)
#Setting the column names to be that used in the dataset
colnames(regression) <- tolower(colnames(regression))
#numerical summary and histograms of variables of interest
#Starting with normexam
#stat.desc is a function form pastecs - make sure you include the basic switch=F and the format to ensure you don't get scienfitic notation
format(stat.desc(regression$normexam), scientific=FALSE)
#skewness and kurtosis from semTools with standard error
skew<-semTools::skew(regression$normexam)
kurt<-semTools::kurtosis(regression$normexam)
#We divide the skew statistic by the standard error to get the standardised score
skew[1]/skew[2]
kurt[1]/kurt[2]
#Both are falling with the 95% CI
#We will allocate the histogram to a variable to allow use to manipulate it
gg <- ggplot(regression, aes(x=regression$normexam))
#Change the label of the x axis
gg <- gg + labs(x="Normalised Exam Score Age 16")
#manage binwidth and colours
gg <- gg + geom_histogram(binwidth=2, colour="black", aes(y=..density.., fill=..count..))
gg <- gg + scale_fill_gradient("Count", low="#DCDCDC", high="#7C7C7C")
#adding a normal curve
#use stat_function to compute a normalised score for each value of normexam
#pass the mean and standard deviation
#use the na.rm parameter to say how missing values are handled
gg <- gg + stat_function(fun=dnorm, color="red",args=list(mean=mean(regression$normexam, na.rm=TRUE), sd=sd(regression$normexam, na.rm=TRUE)))
#to display the graph request the contents of the variable be shown
gg
#Create a qqplot
qqnorm(regression$normexam)
qqline(regression$normexam, col=2) #show a line on theplot
#Now for Standlrt
#stat.desc is a function form pastecs - make sure you include the basic switch=F to ensure you don't get scienfitic notation
format(stat.desc(regression$standlrt, basic=F), scientific=FALSE)
#skewness and kurtosis from semTools with standard error
skew<-semTools::skew(regression$standlrt)
#skewness is an issue
kurt<-semTools::kurtosis(regression$standlrt)
#We divide the skew statistic by the standard error to get the standardised score
skew[1]/skew[2]
kurt[1]/kurt[2]
#Skewness is an issue so we need to look at the scores (these are already standardised)
#Using +/- 3.29 as our bounds we can treat our data as normal
#We will allocate the histogram to a variable to allow use to manipulate it
gg <- ggplot(regression, aes(x=regression$standlrt))
#Change the label of the x axis
gg <- gg + labs(x="Score on Standard Reading Test Age 11")
#manage binwidth and colours
gg <- gg + geom_histogram(binwidth=2, colour="black", aes(y=..density.., fill=..count..))
gg <- gg + scale_fill_gradient("Count", low="#DCDCDC", high="#7C7C7C")
#adding a normal curve
#use stat_function to compute a normalised score for each value of standlrt
#pass the mean and standard deviation
#use the na.rm parameter to say how missing values are handled
gg <- gg + stat_function(fun=dnorm, color="red",args=list(mean=mean(regression$standlrt, na.rm=TRUE), sd=sd(regression$standlrt, na.rm=TRUE)))
#to display the graph request the contents of the variable be shown
gg
#Create a qqplot
qqnorm(regression$standlrt)
qqline(regression$standlrt, col=2) #show a line on theplot
# Chunk 3
cor.test(regression$normexam, regression$standlrt, method='pearson')
# Chunk 1: setup
knitr::opts_chunk$set(echo = TRUE)
# Chunk 2
#Inspecting the data
#Remember to install these packages if you haven't already done so
library(foreign)
library(pastecs) #For creating descriptive statistic summaries
library(ggplot2) #For creating histograms with more detail than plot
library(psych) # Some useful descriptive functions
library(semTools) #For skewness and kurtosis
library(car) # For Levene's test for homogeneity of variance
#Read in the file
regression <- read.spss("Regression.sav", use.value.labels=TRUE, max.value.labels=Inf, to.data.frame=TRUE)
#Setting the column names to be that used in the dataset
colnames(regression) <- tolower(colnames(regression))
#numerical summary and histograms of variables of interest
#Starting with normexam
#stat.desc is a function form pastecs - make sure you include the basic switch=F and the format to ensure you don't get scienfitic notation
format(stat.desc(regression$normexam), scientific=FALSE)
#skewness and kurtosis from semTools with standard error
skew<-semTools::skew(regression$normexam)
kurt<-semTools::kurtosis(regression$normexam)
#We divide the skew statistic by the standard error to get the standardised score
skew[1]/skew[2]
kurt[1]/kurt[2]
#Both are falling with the 95% CI
#We will allocate the histogram to a variable to allow use to manipulate it
gg <- ggplot(regression, aes(x=regression$normexam))
#Change the label of the x axis
gg <- gg + labs(x="Normalised Exam Score Age 16")
#manage binwidth and colours
gg <- gg + geom_histogram(binwidth=2, colour="black", aes(y=..density.., fill=..count..))
gg <- gg + scale_fill_gradient("Count", low="#DCDCDC", high="#7C7C7C")
#adding a normal curve
#use stat_function to compute a normalised score for each value of normexam
#pass the mean and standard deviation
#use the na.rm parameter to say how missing values are handled
gg <- gg + stat_function(fun=dnorm, color="red",args=list(mean=mean(regression$normexam, na.rm=TRUE), sd=sd(regression$normexam, na.rm=TRUE)))
#to display the graph request the contents of the variable be shown
gg
#Create a qqplot
qqnorm(regression$normexam)
qqline(regression$normexam, col=2) #show a line on theplot
#Now for Standlrt
#stat.desc is a function form pastecs - make sure you include the basic switch=F to ensure you don't get scienfitic notation
format(stat.desc(regression$standlrt, basic=F), scientific=FALSE)
#skewness and kurtosis from semTools with standard error
skew<-semTools::skew(regression$standlrt)
#skewness is an issue
kurt<-semTools::kurtosis(regression$standlrt)
#We divide the skew statistic by the standard error to get the standardised score
skew[1]/skew[2]
kurt[1]/kurt[2]
#Skewness is an issue so we need to look at the scores (these are already standardised)
#Using +/- 3.29 as our bounds we can treat our data as normal
#We will allocate the histogram to a variable to allow use to manipulate it
gg <- ggplot(regression, aes(x=regression$standlrt))
#Change the label of the x axis
gg <- gg + labs(x="Score on Standard Reading Test Age 11")
#manage binwidth and colours
gg <- gg + geom_histogram(binwidth=2, colour="black", aes(y=..density.., fill=..count..))
gg <- gg + scale_fill_gradient("Count", low="#DCDCDC", high="#7C7C7C")
#adding a normal curve
#use stat_function to compute a normalised score for each value of standlrt
#pass the mean and standard deviation
#use the na.rm parameter to say how missing values are handled
gg <- gg + stat_function(fun=dnorm, color="red",args=list(mean=mean(regression$standlrt, na.rm=TRUE), sd=sd(regression$standlrt, na.rm=TRUE)))
#to display the graph request the contents of the variable be shown
gg
#Create a qqplot
qqnorm(regression$standlrt)
qqline(regression$standlrt, col=2) #show a line on theplot
# Chunk 3
cor.test(regression$normexam, regression$standlrt, method='pearson')
knitr::opts_chunk$set(echo = TRUE)
#We are using a .dat file (survey.dat) created from the SPSS file survey.sav  taken from SPSS Survival Manual 6th Edition Julie Pallant
#http://spss.allenandunwin.com.s3-website-ap-southeast-2.amazonaws.com/data-files.html#.Wb0vvnWP-po
#Results on a survey on well being
#We need to load the file so that we can use it in R.
survey <- read.table("C:/tempR/survey.dat")
#Setting the column names to be that used in the dataset
colnames(survey) <- tolower(colnames(survey))
#Inspecting the data
#Remember to install these packages if you haven't already done so
library(pastecs) #For creating descriptive statistic summaries
library(ggplot2) #For creating histograms with more detail than plot
library(psych) # Some useful descriptive functions
library(semTools) #For skewness and kurtosis
library(car) # For Levene's test for homogeneity of variance
colnames(col())
#We are using a .dat file (survey.dat) created from the SPSS file survey.sav  taken from SPSS Survival Manual 6th Edition Julie Pallant
#http://spss.allenandunwin.com.s3-website-ap-southeast-2.amazonaws.com/data-files.html#.Wb0vvnWP-po
#Results on a survey on well being
#We need to load the file so that we can use it in R.
survey <- read.table("C:/tempR/survey.dat")
#Setting the column names to be that used in the dataset
colnames(survey) <- tolower(colnames(survey))
#Inspecting the data
#Remember to install these packages if you haven't already done so
library(pastecs) #For creating descriptive statistic summaries
library(ggplot2) #For creating histograms with more detail than plot
library(psych) # Some useful descriptive functions
library(semTools) #For skewness and kurtosis
library(car) # For Levene's test for homogeneity of variance
#Get descriptive stastitics by group
#describeBy is part of the psych package so you need to use it
psych::describeBy(survey$tslfest,group=survey$sex)
#Conduct Levene's test for homogeneity of variance in library car
ltest<-car::leveneTest(tslfest ~ sex, data=survey)
ltest
ltest.df1
knitr::opts_chunk$set(echo = TRUE)
#We are using a .dat file (survey.dat) created from the SPSS file survey.sav  taken from SPSS Survival Manual 6th Edition Julie Pallant
#http://spss.allenandunwin.com.s3-website-ap-southeast-2.amazonaws.com/data-files.html#.Wb0vvnWP-po
#Results on a survey on well being
#We need to load the file so that we can use it in R.
survey <- read.table("C:/tempR/survey.dat")
#Setting the column names to be that used in the dataset
colnames(survey) <- tolower(colnames(survey))
#Inspecting the data
#Remember to install these packages if you haven't already done so
library(pastecs) #For creating descriptive statistic summaries
library(ggplot2) #For creating histograms with more detail than plot
library(psych) # Some useful descriptive functions
library(semTools) #For skewness and kurtosis
library(car) # For Levene's test for homogeneity of variance
#numerical summary and histograms of variables of interest
#Starting with feeling of control
#stat.desc is a function from pastecs - make sure you include the basic switch=F to ensure you don't get scienfitic notation
pastecs::stat.desc(survey$tpcoiss, basic=F)
#skewness and kurtosis from semTools with standard error
tpskew<-semTools::skew(survey$tpcoiss)
tpkurt<-semTools::kurtosis(survey$tpcoiss)
#We divide the skew statistic by the standard error to get the standardised score
tpskew[1]/tpskew[2]
tpkurt[1]/tpkurt[2]
#We will allocate the histogram to a variable to allow use to manipulate it
gg <- ggplot(survey, aes(x=survey$tpcoiss))
#Change the label of the x axis
gg <- gg + labs(x="Feeling of Control")
#manage binwidth and colours
gg <- gg + geom_histogram(binwidth=2, colour="black", aes(y=..density.., fill=..count..))
gg <- gg + scale_fill_gradient("Count", low="#DCDCDC", high="#7C7C7C")
#adding a normal curve
#use stat_function to compute a normalised score for each value of tpcois
#pass the mean and standard deviation
#use the na.rm parameter to say how missing values are handled
gg <- gg + stat_function(fun=dnorm, color="red",args=list(mean=mean(survey$tpcoiss, na.rm=TRUE), sd=sd(survey$tpcoiss, na.rm=TRUE)))
#to display the graph request the contents of the variable be shown
gg
#Create a qqplot
qqnorm(survey$tpcoiss)
qqline(survey$tpcoiss, col=2) #show a line on theplot
#Create standardised scores and sort
sort(scale(survey$tpcoiss))
#Repeat for the variable representing feelings of stress
pastecs::stat.desc(survey$tpstress, basic=F)
semTools::skew(survey$tpstress)
semTools::kurtosis(survey$tpstress)
gs <- ggplot(survey, aes(x=survey$tpstress))
gs <- gs + labs(x="Perceived Stress")
gs <- gs + geom_histogram(binwidth=2, colour="black", aes(y=..density.., fill=..count..))
gs <- gs + scale_fill_gradient("Count", low="#DCDCDC", high="#7C7C7C")
gs <- gs + stat_function(fun=dnorm, color="red",args=list(mean=mean(survey$tpstress, na.rm=TRUE), sd=sd(survey$tpstress, na.rm=TRUE)))
gs
#Create a qqplot
qqnorm(survey$tpstress)
qqline(survey$tpstress, col=2) #show a line on theplot
#Sort the standardised scores
sort(scale(survey$tpstress))
#Simple scatterplot of feeling of control and perceived stress
#aes(x,y)
scatter <- ggplot(survey, aes(survey$tpstress, survey$tpcoiss))
scatter + geom_point() + labs(x = "Total Perceived Stress", y = "Total PCOISS")
#Add a regression line
scatter + geom_point() + geom_smooth(method = "lm", colour = "Red", se = F) + labs(x = "Total Perceived Stress", y = "Total PCOISS")
#Pearson Correlation
stats::cor.test(survey$tpcoiss, survey$tpstress, method='pearson')
#Spearman Correlation
#Change the method to be spearman.
#This test will give an error since this method uses ranking but cannot handle ties
cor.test(survey$tpcoiss, survey$tpstress, method = "spearman")
#We can also use kendall's tau which does handle ties
cor.test(survey$tpcoiss, survey$tpstress, method = "kendall")
#Get descriptive stastitics by group
#describeBy is part of the psych package so you need to use it
psych::describeBy(survey$tslfest,group=survey$sex)
#Conduct Levene's test for homogeneity of variance in library car
car::leveneTest(tslfest ~ sex, data=survey)
#Conduct the t-test from package stats
#You can use the var.equal = TRUE option to specify equal variances and a pooled variance estimate
stats::t.test(tslfest~sex,var.equal=TRUE,data=survey)
drinkset<- read.table("C:/tempR/Field-BDI-Non-parametric.dat")
#Get your descriptive statistcs
describeBy(drinkset$bdisun,group=drinkset$drink)
#Create data subsets for each drink
vodkadata <- subset(drinkset, drink=1)
beerdata <-subset(drinkset, drink=2)
#Create plots of these
gs <- ggplot(vodkadata, aes(x=vodkadata$bdisun))
gs <- gs + labs(x="Vodka")
gs <- gs + geom_histogram(binwidth=2, colour="black", aes(y=..density.., fill=..count..))
gs <- gs + scale_fill_gradient("Count", low="#DCDCDC", high="#7C7C7C")
gs <- gs + stat_function(fun=dnorm, color="red",args=list(mean=mean(vodkadata$bdisun, na.rm=TRUE), sd=sd(vodkadata$bdisun, na.rm=TRUE)))
gs
gs <- ggplot(beerdata, aes(x=beerdata$bdisun))
gs <- gs + labs(x="Beer")
gs <- gs + geom_histogram(binwidth=2, colour="black", aes(y=..density.., fill=..count..))
gs <- gs + scale_fill_gradient("Count", low="#DCDCDC", high="#7C7C7C")
gs <- gs + stat_function(fun=dnorm, color="red",args=list(mean=mean(beerdata$bdisun, na.rm=TRUE), sd=sd(beerdata$bdisun, na.rm=TRUE)))
gs
# Test for differences on  Sunday
stats::wilcox.test(bdisun~drink, data=drinkset)
# Test for differences on Wednesday
wilcox.test(bdiwed~drink, data=drinkset)
ltest$df1
ltest[1]
#Pr(F) is your probability
#to get a p-value more familar use this forumla
#pf(F_stat, df1, df2, lower.tail = FALSE)
ltest
#Pr(F) is your probability
#to get a p-value more familar use this forumla
#pf(F_stat, df1, df2, lower.tail = FALSE)
pf(2.574, 1, 434, lower.tail = FALSE)
#Get descriptive stastitics by group
#describeBy is part of the psych package so you need to use it
psych::describeBy(survey$tslfest,group=survey$sex)
#Conduct Levene's test for homogeneity of variance in library car
ltest<-car::leveneTest(tslfest ~ sex, data=survey)
tapply(survey$tslfest, summary$sex, summary)
tapply(survey$tslfest, survey$sex, summary)
?tapply
describe.by(survey$tslfest, survey$sex, mat=true)
tapply(survey$tslfest, survey$sex, mean)
tapply(survey$tslfest, survey$sex, sd)
#Get descriptive stastitics by group
tapply(survey$tslfest, survey$sex, mean)
tapply(vector, index, function)
#Get descriptive stastitics by group
tapply(survey$tslfest, 1, mean)
#Get descriptive stastitics by group
tapply(survey$tslfest, survey$sex, summary)
#Get descriptive stastitics by group
tapply(survey$tslfest, as.numeric(survey$sex), summary)
#Get descriptive stastitics by group
tapply(survey$tslfest, as.numeric(survey$sex), mean)
#Get descriptive stastitics by group
describe.by(survey$tslfest, as.numeric(survey$sex))
#Get descriptive stastitics by group
describeby(survey$tslfest, as.numeric(survey$sex))
#Get descriptive stastitics by group
describeBy(survey$tslfest, as.numeric(survey$sex))
survey$tslfest, as.numeric(survey$sex)
describeBy(survey$tslfest, as.numeric(survey$sex))
#Get descriptive stastitics by group
describeBy(survey$tslfest, survey$sex)
describeBy(survey$tslfest, survey$sex)
#Conduct the t-test from package stats
#You can use the var.equal = TRUE option to specify equal variances and a pooled variance estimate
stats::t.test(tslfest~sex,var.equal=TRUE,data=survey)
drinkset<- read.table("C:/tempR/Field-BDI-Non-parametric.dat")
#Get your descriptive statistcs
describeBy(drinkset$bdisun,group=drinkset$drink)
#Create data subsets for each drink
vodkadata <- subset(drinkset, drink=1)
beerdata <-subset(drinkset, drink=2)
#Create plots of these
gs <- ggplot(vodkadata, aes(x=vodkadata$bdisun))
gs <- gs + labs(x="Vodka")
gs <- gs + geom_histogram(binwidth=2, colour="black", aes(y=..density.., fill=..count..))
gs <- gs + scale_fill_gradient("Count", low="#DCDCDC", high="#7C7C7C")
gs <- gs + stat_function(fun=dnorm, color="red",args=list(mean=mean(vodkadata$bdisun, na.rm=TRUE), sd=sd(vodkadata$bdisun, na.rm=TRUE)))
gs
gs <- ggplot(beerdata, aes(x=beerdata$bdisun))
gs <- gs + labs(x="Beer")
gs <- gs + geom_histogram(binwidth=2, colour="black", aes(y=..density.., fill=..count..))
gs <- gs + scale_fill_gradient("Count", low="#DCDCDC", high="#7C7C7C")
gs <- gs + stat_function(fun=dnorm, color="red",args=list(mean=mean(beerdata$bdisun, na.rm=TRUE), sd=sd(beerdata$bdisun, na.rm=TRUE)))
gs
# Test for differences on  Sunday
stats::wilcox.test(bdisun~drink, data=drinkset)
# Test for differences on Wednesday
wilcox.test(bdiwed~drink, data=drinkset)
#Paired T-test:
#t.test(y1,y2,paired=TRUE) # where y1 & y2 are numeric
#Experiment - fear of statistics
edata<-read.table('experim.dat')
# Difference between FearFor our example:
t.test(edata$fost1,edata$fost2,paired=TRUE)
install.packages("coin")
library(coin)
# Test for differences on  Sunday
coin::wilcox.test(bdisun~drink, data=drinkset)
# Test for differences on  Sunday
coin::wilcox_test(bdisun~drink, data=drinkset)
# Test for differences on Wednesday
coin::wilcox_test(bdiwed~drink, data=drinkset)
wilcox.test(vodkadata$bdisun,vodkadata$bdiwed,paired=TRUE)
coin::wilcox_test(vodkadata$bdisun,vodkadata$bdiwed,paired=TRUE)
?coin wilcox.test
?wilcox_test
#Non-parametric Repeated measure
#We are using the drink dataset again
#Need to split the file or subset it  and run against each sub-set
vodkadata<-subset(drinkset,drinkset$Drink=='vodka')
wilcox.test(vodkadata$bdisun,vodkadata$bdiwed,paired=TRUE)
#Non-parametric Repeated measure
#We are using the drink dataset again
#Need to split the file or subset it  and run against each sub-set
vodkadata<-subset(drinkset,drinkset$Drink=='vodka')
#Wilcoxon test syntax
#stats::wilcox.test(y1,y2,paired=TRUE)
wilcox.test(vodkadata$bdisun,vodkadata$bdiwed,paired=TRUE)
#Non-parametric Repeated measure
#We are using the drink dataset again
#Need to split the file or subset it  and run against each sub-set
vodkadata<-subset(drinkset,drinkset$Drink=='beer')
wilcox.test(vodkadata$bdisun,vodkadata$bdiwed,paired=TRUE)
#Non-parametric Repeated measure
#We are using the drink dataset again
#Need to split the file or subset it  and run against each sub-set
vodkadata<-subset(drinkset,drinkset$Drink=='Vodka')
wilcox.test(vodkadata$bdisun,vodkadata$bdiwed,paired=TRUE)
#Non-parametric Repeated measure
#We are using the drink dataset again
#Need to split the file or subset it  and run against each sub-set
vodkadata<-subset(drinkset,drinkset$Drink=='vodka')
vodkadata<-subset(drinkset,drinkset$Drink=='vodka')
vodkadata$bdisun
drinkset<- read.table("C:/tempR/Field-BDI-Non-parametric.dat")
vodkadata<-subset(drinkset,drinkset$Drink=='vodka')
vodkadata$bdisun
#Non-parametric Repeated measure
#We are using the drink dataset again
#Need to split the file or subset it  and run against each sub-set
vodkadata<-subset(drinkset,drinkset$Drink=='Vodka')
vodkadata$bdisun
summary(vodkadata$bdisun)
#Non-parametric Repeated measure
#We are using the drink dataset again
#Need to split the file or subset it  and run against each sub-set
vodkadata<-subset(drinkset,drinkset$Drink==‘vodka’)
#Non-parametric Repeated measure
#We are using the drink dataset again
#Need to split the file or subset it  and run against each sub-set
vodkadata<-subset(drinkset,drinkset$Drink=='vodka')
summary(vodkadata$bdisun)
wilcox.test(vodkadata$bdisun,vodkadata$bdiwed,paired=TRUE)
vodkadata<-subset(drinkset,drinkset$Drink=='Vodka')
summary(vodkadata$bdisun)
summary(vodkadata)
#Non-parametric Repeated measure
#We are using the drink dataset again
#Need to split the file or subset it  and run against each sub-set
vodkadata<-subset(drinkset,Drink=='Vodka')
#Non-parametric Repeated measure
#We are using the drink dataset again
#Need to split the file or subset it  and run against each sub-set
vodkadata<-subset(drinkset,drink=='Vodka')
summary(vodkadata)
#Non-parametric Repeated measure
#We are using the drink dataset again
#Need to split the file or subset it  and run against each sub-set
vodkadata<-subset(drinkset,drinkset$drink=='Vodka')
wilcox.test(vodkadata$bdisun,vodkadata$bdiwed,paired=TRUE)
#Non-parametric Repeated measure
#We are using the drink dataset again
#Need to split the file or subset it  and run against each sub-set
vodkadata<-subset(drinkset,drinkset$drink=='vodka')
wilcox.test(vodkadata$bdisun,vodkadata$bdiwed,paired=TRUE)
#Non-parametric Repeated measure
#We are using the drink dataset again
#Need to split the file or subset it  and run against each sub-set
vodkadata<-subset(drinkset,drinkset$drink=='Vodka')
wilcox.test(vodkadata$bdisun,vodkadata$bdiwed,paired=TRUE)
stats::wilcox.test(vodkadata$bdisun,vodkadata$bdiwed,paired=TRUE)
summary(vodkadata)
beerdata<-subset(drinkset,drinkset$drink=='Beer')
summary(beerdata)
stats::wilcox.test(beerdata$bdisun,beerdata$bdiwed,paired=TRUE)
stats::wilcox.test(vodkadata$bdisun,vodkadata$bdiwed,paired=TRUE)
