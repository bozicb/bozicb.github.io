% Filename  : samplepaper.tex
% Purpose   : A sample exam paper to demonstrate how to use the 'ditpaper'
%             TeX class.
% Author    : Emmet Caulfield
% Revision  : $Id: samplepaper.tex 2 2006-02-19 20:34:45Z emmet $
% Repository: $HeadURL: http://svn.netrogen.lan/tex-ditpaper/trunk/samplepaper.tex $
%

% 'nosolution' (default) and 'solution' toggle the inclusion of solutions
% in the output. The tag solution, below, is replaced by 'sed' 
% in the Makefile to cause both the paper and the solutions to be produced.
%\documentclass[solution]{ditpaper}

\documentclass[solution]{ditpaper}
%\documentclass[solution]{ditpaper}

%\usepackage{epsf}
\usepackage{fleqn}
%\usepackage{rotating}
\usepackage{graphicx}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% Start newcommand defs taken from aima slides style file %%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\def\mysum{\begin{Huge}\mbox{$\Sigma$}\end{Huge}}
\def\myint{\begin{LARGE}\mbox{$\int$}\end{LARGE}}
\def\myprod{\begin{Huge}\mbox{$\Pi$}\end{Huge}}

\newcommand{\smbf}[1]{\mbox{{\smathbold #1}}}
\newcommand{\mbf}[1]{\mbox{{\bf #1}}}

%%%%%% logical symbols
\newcommand{\entails}{\models}
\newcommand{\implies}{\:\;{\Rightarrow}\:\;}
\newcommand{\textimplies}{\;{\Rightarrow}\;}
\newcommand{\impliessymbol}{\Rightarrow}
\newcommand{\lequiv}{\;\;{\Leftrightarrow}\;\;}
\newcommand{\textlequiv}{\;{\Leftrightarrow}\;}
\newcommand{\lequivsymbol}{\Leftrightarrow}
\newcommand{\xor}{\not\lequiv}
\newcommand{\All}[1]{\forall\,#1\;\;}
\newcommand{\Exi}[1]{\exists\,#1\;\;}
\newcommand{\Exii}[1]{\exists!\,#1\;\;}% -pnorvig
\newcommand{\Iot}[2]{\iota\,#1\,#2}
\newcommand{\Lam}[2]{\lambda #1\;#2}
\newcommand{\Qua}[3]{[#1\,#2\;#3]}

\newcommand{\union}{{\,{\cup}\,}}
\newcommand{\intersection}{{\,{\cap}\,}}
\renewcommand{\emptyset}{\{\,\}}
\newcommand{\emptylist}{[\,]}
\newcommand{\adjoin}[2]{\{#1|#2\}}
\newcommand{\elt}{{\,{\in}\,}}  %%%cuts down on spacing
\newcommand{\eq}{{\,{=}\,}}  %%%cuts down on spacing
\def\stimes{{\,\times\,}}       %%%cuts down on spacing

\newcommand{\sr}[1]{\mathrel{\raisebox{-0.6ex}{$\stackrel{#1}{\longrightarrow}$}}}
\newcommand{\srbox}[1]{\sr{\fboxsep=1pt\fbox{$\,{\scriptstyle #1}\,$}}}
\newcommand{\srboxbox}[1]{\sr{\fboxsep=1pt\fbox{\fbox{$\,{\scriptstyle #1}\,$}}}}

\def\Diff{\mbox{{\it Diff}}}

%%%%%% probability and decision theory
\newcommand{\pv}{\mbf{P}}
\newcommand{\qv}{\mbf{Q}}
\newcommand{\given}{\mid}
\def\transition#1#2{q(#1\rightarrow #2)}
\newcommand{\otherthan}{\overline}
\newcommand{\Parents}{Parents}
\newcommand{\parents}{parents}
\newcommand{\Children}{Children}
\newcommand{\children}{children}
\newcommand{\MarkovBlanket}{MB}
\newcommand{\markovBlanket}{mb}

\def\X{\mbf{X}}
\def\x{\mbf{x}}
\def\sx{\smbf{x}}
\def\Y{\mbf{Y}}
\def\y{\mbf{y}}
\def\sy{\smbf{y}}
\def\E{\mbf{E}}
\def\e{\mbf{e}}
\def\D{\mbf{D}}
\def\d{\mbf{d}}
\def\sbe{\smbf{e}}
\def\sE{\smbf{E}}
\def\T{\mbf{T}}
\def\O{\mbf{O}}
\def\se{\smbf{e}}
\def\Z{\mbf{Z}}
\def\z{\mbf{z}}
\def\sz{\smbf{z}}
\def\F{\mbf{F}}
\def\f{\mbf{f}}
\def\A{\mbf{A}}
\def\B{\mbf{B}}
\def\C{\mbf{C}}
\def\b{\mbf{b}}
\def\m{\mbf{m}}
\def\I{\mbf{I}}
\def\H{\mbf{H}}
\def\zeroes{\mbf{0}}
\def\ones{\mbf{1}}
\def\ev{\mbf{ev}}
\def\fv{\mbf{ev}}
\def\sv{\mbf{sv}}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% End newcommand defs taken from aima slides style file %%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%





% These must be set or bizarre defaults will be used:
\facility{Kevin Street, Dublin 8}
\course{BSc. (Hons) in Computer Science}
\examcode{S228/419C}
\stage{Stage 4}
\session{Semester 2 Examinations 2012/2013}
\title{Artificial Intelligence II}
\examiners{Dr. John Kelleher\\
Dr. Deirdre. Lillis\\
Mr. D. Tracey}
\examdate{Monday\\$13^{th}$ May 2013}
\examtime{\centerline{4:00 p.m to 6:00 p.m}}
\instructions{Question 1 is \textbf{compulsory}\par{} Answer Question 1 (40 marks) \textbf{and}\par{} any 2 Other Questions (30 marks each).}

\begin{document}


%aima chapters 18
% inductive bias, learning theory - supervised/unsupervised, overfitting, lazy/eager learner, classification v regression, false positive v false negatives, linear separability, consistency, evaluation

\question
\begin{enumerate}
	\item Explain what is meant by \textbf{inductive learning}.
	\marks{5}
	\begin{answer}
		Inductive Learning involves the process of learning by example where a system tries to induce a general rule from a set of observed instances.
	\end{answer}
		\item In the context of machine learning, explain what is meant by \textbf{overfitting} the training data.
	\marks{5}
	\begin{answer}
		Overfitting occurs when classifiers make decisions based on accidental properties of the training set that will lead to errors on the test set (or new data). As a result, whenever there is a large set of possible hypotheses, one has to be careful not to use the resulting freedom to find meaningless "regularity" in the data.
	\end{answer}	
		\item  Inductive machine learning is often referred to as an \textbf{ill-posed problem}. What is meant by this?
	\marks{15}
	\begin{answer}
		Inductive machine learning algorithms essentially search through a hypothesis space to find a the best hypothesis that is consistent with the training data used. It is possible to find multiple hypotheses that are  consistent with a given training set (i.e. agrees with all training examples).  It is for this reason that inductive machine learning is referred to as an ill-posed problem as there is typically not enough information in the training data used to build a model to choose a single best hypothesis. Inductive machine learning algorithms must somehow choose one of the available hypotheses as the \emph{best}. An example like that shown in the figure below would be useful at this point
		\begin{center}
			\includegraphics[width=5cm]{./images/curve-fitting5.png}
		\end{center}
	\end{answer}
	\item  In the context of machine learning, explain what is meant by the term \textbf{inductive bias} and illustrate your explanation using examples of inductive biases used by machine learning algorithms.
	\marks{15}
	\begin{answer}
		\begin{itemize}
				\item The inductive bias of a learning algorithm:
				\begin{enumerate}
					\item is a set of assumption about what the true function we are trying to model looks like.
					\item defines the set of hypotheses that a learning algorithm considers when it is learning.
					\item guides the learning algorithm to prefer one hypothesis (i.e. the hypothesis that best fits with the assumptions) over the others. 
					\item is a necessary prerequisite for learning to happen because inductive learning is an ill posed problem. 
				\end{enumerate}	
				\item An example of the specific inductive bias introduced by particular machine learning algorithms would be good here. E.g.:		
				\begin{itemize}
					\item Maximum margin: when drawing a boundary between two classes, attempt to maximize the width of the boundary. This is the bias used in Support Vector Machines. The assumption is that distinct classes tend to be separated by wide boundaries.
					\item Minimum cross-validation error: when trying to choose among hypotheses, select the hypothesis with the lowest cross-validation error.
				\end{itemize}
			\end{itemize}
	\end{answer}
\end{enumerate}


\newpage

%Q2
% knn and CBR 
% information theory, entropy, Decision Trees, Inductive logic programming

\begin{table}[htdp]
\caption{Dataset for the 3-Nearest Neighbor question}
\begin{center}
\begin{tabular}{|c|c|c|c|}
\hline
ID & Feature 1 & Feature 2  & Target \\
\hline
101 & 4 &	180000 & C1\\
102 & 3 &	120000 & C2\\
103 & 7 &	360000 & C2\\
104 & 5 &	420000 &	C1\\
105 & 8 &	480000 &	C2\\
\hline
\end{tabular}
\end{center}
\label{tab:3nn-data}
\end{table}%

\begin{table}[htdp]
\caption{Query instance for the 3-Nearest Neighbor question.}
\begin{center}
\begin{tabular}{|c|c|c|c|}
\hline
ID & Feature 1 & Feature 2  & Target \\
\hline
250 & 4 &	240000 & ?\\
\hline
\end{tabular}
\end{center}
\label{tab:3nn-query}
\end{table}%
			
\question 
	\begin{enumerate}	
		\item Table \ref{tab:3nn-data} lists a dataset containing examples described by two descriptive features, \textbf{Feature 1} and \textbf{Feature 2}, and labelled with a target class \textbf{Target}. Table \ref{tab:3nn-query} lists the details of a query for which we want to predict the target label. We have decided to use a \textbf{3-Nearest Neighbor} model for this prediction and we will use Euclidean distance as our distance metric: 
								\begin{center}
								$d(x_1,x_2)=\sqrt{\sum_{i=1}^{n} \left(\left(x_1.f_i - x_2.f_i \right)^2 \right)}$
								\end{center}					
		\begin{enumerate}
				\item With which target class (\textbf{C1}  or \textbf{C2}) will our \textbf{3-Nearest Neighbor} model label the query? Provide an explanation for your answer.				
			  \marks{8}
				\begin{answer}
					The first stage is to calculate the Euclidean distance between each of the examples and the query:
					\begin{center}
						\begin{tabular}{|c|c|}
						ID & Euclidean Distance \\
						\hline
						101 & 60000\\
						102 & 120000\\
						103 & 120000\\
						104 & 180000\\
						105 & 240000\\
						\hline
						\end{tabular}
					\end{center}
				 From this table we can see that the three closest examples to the query are examples 101, 102, and 103. Example 101 has a target label of C1 and both 102 and 103 have target labels C2. Consequently C2 is the majority label in local model constructed by the 3-Nearest Neighbor classifier for this query instance and the query will be labelled with class C2.
				\end{answer}
			\item There is a large variation in range between \textbf{Feature 1} and \textbf{Feature 2}. To account for this we decide to normalize the data. Compute the normalized versions of Feature 1 and Feature 2  to four decimal places of precision using range normalization 
								\begin{center}
								$x_i.f^\prime=\frac{x_i.f - min(f)}{max(f)-min(f)}$
								\end{center}		
				\marks{4}
				\begin{answer}
					\begin{center}
\begin{tabular}{|c|c|c|c|}
\hline
ID & Feature 1 & Feature 2  & Target \\
\hline
101 &	0.2 &	 0.1667 &	C1\\
102 &	0    & 	0.0000 &	C2\\
103 &	0.8 & 	0.6667 &	C2\\
104 &	0.4 &	   0.8333 &	C1\\
105 &	1    & 	1.0000 &	C2\\
\hline
\end{tabular}
					\end{center}
				\end{answer}
			\item Assuming we use the normalized dataset as input, with which target class (\textbf{C1}  or \textbf{C2}) will our \textbf{3-Nearest Neighbor} model label the query? Provide an explanation for your answer.				
			  \marks{8}
				\begin{answer}
					The normalize query instance is:
\begin{center}
\begin{tabular}{|c|c|c|c|}
\hline
ID & Feature 1 & Feature 
2  & Target \\
\hline
250 & 0.2 & 0.3333 & ?\\
\hline
\end{tabular}
\end{center}
				The Euclidean distances between the normalized data and normalized query are: 
					\begin{center}
						\begin{tabular}{|c|c|}
						ID & Euclidean Distance \\
						\hline
101	& 0.1667\\
102	& 0.3887\\
103	& 0.6864\\
104	& 0.5385\\
105	&1.0414\\						
\hline
						\end{tabular}
					\end{center}
From this table we can see that the 3 closest neighbors are: 101, 103 and 104. 101 and 104 are both labelled as class \textbf{C1}. So \textbf{C1} is the majority class in the neighborhood and the query will be labelled as belonging to it.					
				\end{answer}	
		\end{enumerate}
		% Information theory and Decision Trees
		
		\item Table \ref{tab:classification-data}, on the next page, lists a classification dataset. Each instance in the dataset has two descriptive features (Feature 1 and Feature 2) and is classified as either a positive (+) or a negative(-) example. Note that Table \ref{tab:info-eqs}, also on the next page, lists some equations that you may find useful for this question.		
				\begin{enumerate}
			\item Calculate the classification \textbf{entropy} for this dataset.
			\marks{5}
			\begin{answer}
				Entropy is $-\frac{3}{5}log_2\frac{3}{5}-\frac{2}{5}log_2\frac{2}{5}=0.971$
			\end{answer}
			\item Calculate the \textbf{information gain} for Feature 1 and Feature 2.
			\marks{5}
			\begin{answer}
				Entropy for feature 1 = T $-\frac{3}{4}log_2\frac{3}{4}-\frac{1}{4}log_2\frac{1}{4}=0.811$\\
				Entropy for feature 1 = F $0-\frac{1}{1}log_2\frac{1}{1}=0$\\
				Gain for attribute 1 $0.971-(\frac{4}{5}\times0.811+\frac{1}{5}\times0)=0.322$\\
				Entropy for feature 2 = T $-\frac{2}{3}log_2\frac{2}{3}-\frac{1}{3}log_2\frac{1}{3}=0.918$\\
				Entropy for feature 2 = F $-\frac{1}{2}log_2\frac{1}{2}-\frac{1}{2}log_2\frac{1}{2}=1.0$\\
				Gain for featuree 2 $0.971-(\frac{3}{5}\times0.918+\frac{2}{5}\times1)=0.02$\\
			\end{answer}
		\end{enumerate}
	\end{enumerate}

\newpage

			\begin{table}[htb]
			\begin{center}
			\begin{tabular}{|c|c|c|}
				Feature 1 & Feature 2 & Classification \\
				\hline
				T & T & + \\
				T & F & - \\
				T & F & + \\
				T & T & + \\
				F & T & - \\
			\end{tabular}
			\end{center}
			\caption{Classification dataset for information question.}
			\label{tab:classification-data}
		\end{table}

	\begin{table}[htb]
	\begin{center}
	\begin{tabular}{rl}
	Entropy(DS) & $= -\sum_{i=1}^k p_i \times log_2(p_i)$\\
	Remainder(F) & $=\sum_{v \in Domain(F)} \frac{|DS_v|}{|DS|} Entropy(DS_v)$\\
	InformationGain(F,DS) & $=Entropy(DS)-Remainder(F)$\\
	\end{tabular}
	\end{center}
	\caption{Equations from information theory.}
	\label{tab:info-eqs}
	\end{table}
\newpage
	
%Q3 30 marks
% basic probability 5
% bayesian networks 10
% bayesian learning  15
\begin{table}[!htb]
    \caption{Movie and Song Title Dataset}
    \begin{minipage}{.5\linewidth}
      \centering
\begin{tabular}{l}
\textbf{Movie Titles}\\
\hline
\textit{A Perfect World}\\
\textit{My Perfect Woman}\\
\textit{Pretty World}\\
\hline
\end{tabular}
    \end{minipage}%
    \begin{minipage}{.5\linewidth}
      \centering
\begin{tabular}{l}
\textbf{Song Titles}\\
\hline
\textit{A Perfect Day}\\
\textit{Electric Storm}\\
\textit{Another Rainy Day}\\
\hline
\end{tabular}
    \end{minipage} 
    \label{tab:songmoviedata}
\end{table}

\begin{table}[h]
\caption{Query Title}
\centering
\begin{tabular}{l}
\hline
\textit{Perfect Storm}\\
\hline
\end{tabular}
\label{tab:songmoviequery}
\end{table}


\question Table \ref{tab:songmoviedata} lists a dataset of song and movie titles. Table \ref{tab:songmoviequery} lists the title of a query instance that we would like to classify as being either a movie or a song based on its title. 
	\begin{enumerate}
		\item Using \textbf{Laplacian smoothing}, where 
		\begin{eqnarray*}
		p(x=v) &=& \frac{count(x=v)+k}{count(x) +( k \times |Domain(x)|)}
		\end{eqnarray*}
		with \textbf{k=1} and a \textbf{vocabulary size of 11} calculate the following probabilities:
			\begin{enumerate}
				\item $P(Movie)=?$
				\marks{3}
					\begin{answer}
						$P(Movie) = \frac{3+1}{6 + (1 \times 2)} = \frac{4}{8} = 0.5$
					\end{answer}
				\item $P(Song)=?$
				\marks{3}
					\begin{answer}
						$P(Song) = \frac{3+1}{6 + (1 \times 2)} = \frac{4}{8} = 0.5$
					\end{answer}
				\item $P('Perfect'|Movie)=?$
				\marks{3}
					\begin{answer}
						$P('Perfect'| Movie) = \frac{2+1}{8 + (1 \times 11)} = \frac{3}{19} = 0.1579$
					\end{answer}
				\item $P('Perfect'|Song)=?$
				\marks{3}
					\begin{answer}
						$P('Perfect'|Song) = \frac{1+1}{8 + (1 \times 11)} = \frac{2}{19} = 0.1053$
					\end{answer}
				\item $P('Storm'|Movie)=?$
				\marks{3}
					\begin{answer}
						$P('Storm'|Movie) = \frac{0+1}{8 + (1 \times 11)} = \frac{1}{19} = 0.0526$
					\end{answer}
				\item $P('Storm'|Song)=?$
				\marks{3}
					\begin{answer}
						$P('Storm'|Song) = \frac{1+1}{8 + (1 \times 11)} = \frac{2}{19} = 0.1053$
					\end{answer}
			\end{enumerate}
		\item Calculate the probability of the query title in Table \ref{tab:songmoviequery} belonging to the Movie class under the \textbf{Naive Bayes assumption} and using the \textbf{smoothed probabilities} you calculated in Part (a):		
%Using the smoothed probabilities you calculated in Part 1 of calculate the probability under the \textbf{Naive Bayes assumption} of the query title in Table \ref{tab:songmoviequery} belonging to the Movie class:
			\begin{center}
				$P(Movie|'Perfect~Storm')=?$
			\end{center}
			\marks{8}
			\begin{answer}
				$P(Movie|'Perfect Storm')$ 
				\begin{scriptsize}
				\begin{eqnarray*}
					&=& \frac{P('Perfect'|Movie)P('Storm'|Movie)P(Movie)}{(P('Perfect'|Movie)P('Storm'|Movie)P(Movie))+(P('Perfect'|Song)P('Storm'|Song)P(Song))}\\
					&=& \frac{0.1579 \times 0.0526 \times 0.5}{(0.1579 \times 0.0526 \times 0.5) + (0.1053 \times 0.1053 \times 0.5)}\\
					&=& 0.4286
				\end{eqnarray*}
				\end{scriptsize}
			\end{answer}
		\item Calculate the probability of the query title in Table \ref{tab:songmoviequery} belonging to the Movie class under the \textbf{Naive Bayes assumption} and using \textbf{maximum likelihood} probabilities (i.e. the probabilities we could get if we did not use Laplacian smoothing):	
%Using \textbf{maximum likelihood} probabilities (i.e. do not use Laplacian smoothing in calculating the probabilities) calculate the probability under the \textbf{Naive Bayes assumption} of the query title in Table \ref{tab:songmoviequery} belonging to the Movie class:	
					\begin{center}
				$P(Movie|'Perfect~Storm')=?$
			\end{center}
			\marks{4}
			\begin{answer}
				Because the word 'Storm' does not appear in any of the Movie titles the maximum likelihood (i.e., unsmoothed) probability of $P('Storm'|Movie)=0$. As a result the maximum likelihood probability of $P(Movie|'Perfect~Storm')=0$. Showing the complete calculation: \\
				\\
				$P(Movie|'Perfect Storm')$
				\begin{scriptsize}
				\begin{eqnarray*}
					 &=& \frac{P('Perfect'|Movie)P('Storm'|Movie)P(Movie)}{(P('Perfect'|Movie)P('Storm'|Movie)P(Movie))+(P('Perfect'|Song)P('Storm'|Song)P(Song))}\\
					&=& \frac{\frac{2}{8} \times \frac{0}{8} \times \frac{3}{6}}{(\frac{2}{8} \times \frac{0}{8} \times \frac{3}{6}) + (\frac{1}{8} \times \frac{1}{8} \times \frac{3}{6})}\\
					&=& 0.0
				\end{eqnarray*}
				\end{scriptsize}
			\end{answer}
	\end{enumerate}
%
\newpage

%Q4
%Linear Regression Neural Nets, SVMs, Ensemble Learning

\begin{table}
\begin{center}
\begin{tabular}{cccccc}
\hline
x & 0 & 1 & 2 & 3 & 4\\
\hline
y & 3 & 6 & 7 & 8 & 11\\
\hline
\end{tabular}
\caption{Example Dataset for Linear Regression Question}
\label{tab:linregTab2}
\end{center}
\end{table}

\question 
	\begin{enumerate}
		%Regression Learning
		\item Assuming a domain with one descriptive feature $x$ and one target feature $y$ linear regression uses the following formula to model the relationship between the explanatory and dependent variable: 
	\begin{center}
		$f(x) = w_1x + w0$
	\end{center}
where $w1$ and $w0$ are computed using the following formulae, where $M$ is number of data points in the dataset:
	\begin{center}
		$w_1 =  \frac{(M \sum_{i=1}^M x_i y_i) - (\sum_{i=1}^{M} x_i \sum_{i=1}^{M} y_i)} {(M \sum_{i=1}^{M} x_i^2) - (\sum_{i=1}^{M} x_i)^2}$
	\end{center}
	\begin{center}
		$w_0 = (\frac{1}{M} \sum_{i=1}^{M} y_i) - (\frac{w_1}{M} \sum_{i=1}^{M} x_i)$
	\end{center}
Using the data in Table \ref{tab:linregTab2} compute the values of $w_0$ and $w_1$ that provide the best linear fit to the data.
			\marks{10}
			\begin{answer}
				First we need to compute the values of the equation components:
			\begin{itemize}
				\item M = 5
				\item $\sum_{i=1}^{M} x_i y_i = 0 + 6 + 14 + 24 + 44 = 88$
				\item $\sum_{i=1}^{M} x_i = 10$
			   	\item $\sum_{i=1}^{M} y_i = 35$
			  	\item $\sum_{i=1}^{M} x_i^2 = 0 + 1 + 4 + 9 + 16 = 30$
			  	\item $(\sum_{i=1}^{M} x_i)^2 = 10^2 = 100$
			\end{itemize}
				Given these values,  $w_1$:
				\begin{center}
					\textbf{$w_1= \frac{(5*88)-(10*35)}{(5*30)-100} = \frac{90}{50}=1.8$}
				\end{center}
				And, $w_0$:
				\begin{center}
				\textbf{$w_0= (\frac{1}{5}*35) - (\frac{1.8}{5}*10)= 7-3.6=3.4$}
			\end{center}
			\end{answer}
		
		%Neural Nets	
		\item Figure \ref{fig:nn}, on the next pages, shows a backprogation network that is currently processing the training vector $[1.0, 0.9, 0.9]$ which has an  associated target vector $[0.1, 0.9, 0.1]$. Given that the output from unit B is $0.6$ and from C is $0.8$, and assuming that the activation function used at all nodes in the network is the logistic function, carry out the calculations listed below. Note that Table \ref{tab:nn-eqs}, also on the next page, lists some equations that you may find useful when doing this question. 
\begin{enumerate}
	\item Calculate the actual output vector (to 3 decimal places).
	\marks{10}
		\begin{answer}
		%Output of unit $x = a_x(in_x) = \frac{1}{1 + \exp^{-\sum_j W_{jx} a_j(in_j)}}\\
		%First output unit input $i$\\
		\begin{eqnarray*}
		a_i(in_i) &=&\frac{1}{1 + \exp^{- ((W_{BD} \times a_B(in_B) + (W_{CD} \times a_C(in_C) ))}}\\
		&=&\frac{1}{1 + \exp^{- ((-0.3 \times 0.6) + (0.9 \times 0.8}))}\\
		&=&\frac{1}{1 + \exp^{- 0.54}}\\
		&=&0.632
		\end{eqnarray*}
		%Second output unit input $j$\\
		\begin{eqnarray*}
		a_j(in_j) &=&\frac{1}{1 + \exp^{- ((W_{BE} \times a_B(in_B) + (W_{CE} \times a_C(in_C) ))}}\\
		& = &\frac{1}{1 + \exp^{- ((-0.6 \times 0.6) + (0.1 \times 0.8}))}\\
		& = &\frac{1}{1 + \exp^{- (-0.44)}}\\
		& = &0.392
		\end{eqnarray*}
		%Third output unit input $k$\\
		\begin{eqnarray*}
		a_k(in_k) &=&\frac{1}{1 + \exp^{- ((W_{BF} \times a_B(in_B) + (W_{CF} \times a_C(in_C) ))}}\\
		& = &\frac{1}{1 + \exp^{- ((0.4 \times 0.6) + (1.2 \times 0.8}))}\\
		& = &\frac{1}{1 + \exp^{- 1.2}}\\
		& = &0.769
		\end{eqnarray*}
		\end{answer}
	\item Calculate the \textbf{$\Delta$} error for each output unit (to 3 decimal places).
	\marks{6}
		\begin{answer}
		\begin{eqnarray*}
		\Delta_D& = &(target_D - a_D(in_D)) \times a_D(in_D) \times (1-a_D(in_D))\\
		& = &(0.1-0.632) \times 0.632 \times (1-0.632)\\
		& = &-0.124
		\end{eqnarray*}
%		Second output unit $j$\\
		\begin{eqnarray*}
		\Delta_E& = &(target_E - a_E(in_E)) \times a_E(in_E) \times (1-a_E(in_E))\\
		& = &(0.9-0.392) \times 0.392 \times (1-0.392)\\
		& = &0.121
		\end{eqnarray*}
%		Third output unit $k$\\
		\begin{eqnarray*}
		\Delta_F& = &(target_F - a_F(in_F)) \times a_F(in_F) \times (1-a_F(in_F))\\
		& = &(0.1-0.769) \times 0.769 \times (1-0.769)\\
		& = &-0.119
		\end{eqnarray*}
		\end{answer}
%	\item Calculate the \textbf{$\Delta$} error for each hidden unit B and C. (to 3 decimal places)\\
%		\begin{answer}
%%Again we are using backprop to train a multi-layer network so we use the Delta error rules. In this case the Delta error rule for hidden units.Each hidden node $j$ is responsible for some fraction of the error $\Delta_i$ of each of the output units $i$ to which it connects. Thus the $\Delta_i$ values are divided according to the strengths of the connection between the hidden node and the output nodes and are propagated back to the hidden nodes. Where a hidden node feeds-forward into more than 1 output node the errors propagated back to it are summed. So the error for a hidden unit $j$ feeding into $n$ units= $\Delta_j = a_j(in_j) \times (1-a_j(in_j)) \times \left( \sum_{i=1}^{n}W_{ji} \times \Delta_i \right)$\\
%
%\begin{eqnarray*}
%\Delta_B &=& a_B(in_B) \times (1-a_B(in_B)) \times \left( \sum_{x \in \{D,E,F\}}^{n}W_{Bx} \times \Delta_x \right)\\
%&=& a_B(in_B) \times (1-a_B(in_B)) \times \left(((W_{BD} \times \Delta_D)+(W_{BE} \times \Delta_E)+(W_{BF} \times \Delta_F))\right)\\
%&=& 0.6 \times (1-0.6) \times \left(((-0.3 \times -0.124)+(-0.6 \times 0.121)+(0.4 \times -0.119))\right)\\
%&\approx& -0.020\\
%\end{eqnarray*}
%
%\begin{eqnarray*}
%\Delta_C &=& a_C(in_C) \times (1-a_C(in_C)) \times \left( \sum_{x \in \{D,E,F\}}^{n}W_{Cx} \times \Delta_x \right)\\
%&=& a_C(in_C) \times (1-a_C(in_C)) \times \left(((W_{CD} \times \Delta_D)+(W_{CE} \times \Delta_E)+(W_{CF} \times \Delta_F))\right)\\
%&=& 0.8 \times (1-0.8) \times \left(((0.9 \times -0.124)+(-0.1 \times 0.121)+(1.2 \times -0.119))\right)\\
%&\approx& -0.043\\
%\end{eqnarray*}
%
%		\end{answer}
	\item Calculate the new weight $W_{BD}$ for the connection from unit B to the output unit D after the training example has been processed. Use a learning rate of $\eta = 0.25$.
		\marks{4}
		\begin{answer}
		\begin{eqnarray*}			
		W_{B,D} &=& W_{B,D} + (\eta \times a_B(in_B) \times \Delta_D)\\
				&=& -0.3 + (0.25 \times 0.6 \times -0.124)\\
		           &=& -0.319
		\end{eqnarray*}
	\end{answer}
\end{enumerate}

\end{enumerate}

\clearpage
\newpage

\begin{figure}[htbp]
\begin{center}
\includegraphics[width=3.5in]{./images/backpropnetwork1.png}
\caption{Example Neural Net}
\label{fig:nn}
\end{center}
\end{figure}

	\begin{table}[htb]
	\begin{center}
	\begin{tabular}{ll}
	Weighted sum of inputs for unit $i$ with $j$ inputs:  & $in_i = \sum_j W_{ji} a_j(in_j)$\\
	Activation Function (Logistic) for unit $i$: & $a_i(in_i) = \frac{1}{1 + \exp^{-in_i}}$ \\
	Perceptron weight update rule for link  $j\rightarrow i$ & $w_{ji}=w_{ji} + \eta \left( t_i - a_i(in_i) \right) \times a_j(in_j)$\\
      Hebbian Weight Update Rule for link  $j\rightarrow i$ & $w_{ji} = \eta \times a_j(in_j) \times a_i(in_i)$\\
	Partial Derivative for Logistic Activation Function & $\frac{\delta a_i(in_i)}{\delta in_i}=a_i(in_i) \times (1-a_i(in_i))$\\
	Error for an output unit $i$ & $error_i =  target_i - a_i(in_i)$\\
	Delta Error for an output unit $i$ & $\Delta_i =  error_i \times a_i(in_i) \times (1-a_i(in_i))$\\
	Delta Error for a hidden unit $j$ feeding into $n$ units & $\Delta_j = \left( \sum_{i=1}^{n}W_{ji} \times \Delta_i \right) \times a_j(in_j) \times \left(1-a_j(in_j)\right)$\\
      Delta Weight Update Rule for link $x \rightarrow k$ & $W_{x,k} = W_{x,k} + (\eta \times a_x(in_x) \times \Delta_k)$\\
	\end{tabular}
	\end{center}
	\caption{Equations used in Perceptron and Neural Network training.}
	\label{tab:nn-eqs}
	\end{table}


\end{document}
